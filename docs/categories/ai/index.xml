<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Ai on teraskula.com</title>
    <link>https://teraskula.com/categories/ai/</link>
    <description>Recent content in Ai on teraskula.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 01 Feb 2025 17:32:17 +0700</lastBuildDate><atom:link href="https://teraskula.com/categories/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Gadageni Ai Powered Streamlit App Multi Usage</title>
      <link>https://teraskula.com/posts/gadageni-ai-powered-streamlit-app-multi-usage/</link>
      <pubDate>Sat, 01 Feb 2025 17:32:17 +0700</pubDate>
      
      <guid>https://teraskula.com/posts/gadageni-ai-powered-streamlit-app-multi-usage/</guid>
      <description>&lt;h2 id=&#34;a-journey-into-ai-powered-conversations-and-document-understanding&#34;&gt;A Journey into AI-Powered Conversations and Document Understanding&lt;/h2&gt;
&lt;p&gt;It all started with a simple question: &lt;em&gt;How can we make AI interactions more accessible, intuitive, and useful for everyday users? (me)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In an era where AI models like GPT-4 and Claude are reshaping how we work, learn, and communicate, thereâ€™s still a gap between raw AI capabilities and how people actually interact with them. Many AI-powered tools feel complex, buried under APIs and technical jargon. This is where &lt;strong&gt;Gadageni&lt;/strong&gt; was bornâ€”a vision to create a seamless, user-friendly way for anyone to engage with AI, whether for casual conversation, document analysis, or summarizing the web.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Following Ai News and Papers</title>
      <link>https://teraskula.com/posts/following-ai-news-and-papers/</link>
      <pubDate>Mon, 27 Jan 2025 23:08:28 +0700</pubDate>
      
      <guid>https://teraskula.com/posts/following-ai-news-and-papers/</guid>
      <description>&lt;p&gt;To help me stay sane, i have compiled a list of the latest AI news and in AI research. this is just a note for me&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://paperswithcode.com/&#34;&gt;https://paperswithcode.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://paperswithcode.com/latest&#34;&gt;https://paperswithcode.com/latest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.theneurondaily.com/&#34;&gt;https://www.theneurondaily.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://thesummary.ai/&#34;&gt;https://thesummary.ai/&lt;/a&gt; (some paid)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;thats it
thanks&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Candidate Discovery Demo Qdrant Openai RAG</title>
      <link>https://teraskula.com/posts/candidate-discovery-demo-qdrant-openai/</link>
      <pubDate>Fri, 20 Dec 2024 22:17:10 +0700</pubDate>
      
      <guid>https://teraskula.com/posts/candidate-discovery-demo-qdrant-openai/</guid>
      <description>&lt;h2 id=&#34;candidate-discovery-demo&#34;&gt;Candidate discovery demo&lt;/h2&gt;
&lt;p&gt;In this post will be litle bit technical. continuing what i already created that talk with pdf (RAG).&lt;/p&gt;
&lt;p&gt;combining this &lt;a href=&#34;https://teraskula.com/posts/ollama-chat-from-browser-using-nextjs/&#34;&gt;nextjs from bolt.new chat with ollama&lt;/a&gt; and &lt;a href=&#34;https://teraskula.com/posts/langchain-pdf-ollama-rag/&#34;&gt;langchain for talking with pdf files&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;we will slightly re-architec the app user flow design. before, we use FAISS to store our vector. i am afraid it cannot scale (do not know how to scale). so in search of vector databases. i encounter with bunch of option there is pgai (that really take my interest) still in beta, but also qdrant that already have their enterpise option.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ai Generated Content Emmerge</title>
      <link>https://teraskula.com/posts/ai-generated-content-emmerge/</link>
      <pubDate>Thu, 19 Dec 2024 16:25:05 +0700</pubDate>
      
      <guid>https://teraskula.com/posts/ai-generated-content-emmerge/</guid>
      <description>&lt;h2 id=&#34;is-the-internet-still-could-be-trusted-&#34;&gt;is the internet still could be trusted ?&lt;/h2&gt;
&lt;p&gt;Its bothering me in this last couple of month i am seeing or feel seeing and reading AI generated content. it could be text, images or video.
and i wonder if articles or video was took a day to research and write or create, now, could take a couple of minutes? second?&lt;/p&gt;
&lt;h3 id=&#34;content-creation-before-ai&#34;&gt;Content Creation Before AI&lt;/h3&gt;
&lt;p&gt;Before the adoption of AI, content creation relied heavily on human. The years between 2000 and 2020 (maybe) saw a steady rise in content production, driven by the internet Boom
and Social Media Growth, platforms like Facebook, Twitter, and Instagram introduced new opportunities for user-generated content. and TikTok of course.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Langchain PDF Ollama RAG (Retrieval Augmented Generation)</title>
      <link>https://teraskula.com/posts/langchain-pdf-ollama-rag/</link>
      <pubDate>Mon, 02 Dec 2024 23:12:46 +0700</pubDate>
      
      <guid>https://teraskula.com/posts/langchain-pdf-ollama-rag/</guid>
      <description>&lt;h2 id=&#34;give-pdf-and-talk-about-it&#34;&gt;Give PDF and talk about it&lt;/h2&gt;
&lt;h4 id=&#34;using-lanchain-to-perform-rag-using-ollama-embedings-and-faiss-vectorstore&#34;&gt;using lanchain to perform RAG using Ollama embedings and FAISS vectorstore&lt;/h4&gt;
&lt;p&gt;yeah maybe many tools already provide this kind of feature, But this is different, this is about knowing behind the scene. what actually they do to the pdf files? what actually we do to the text in it? and how the LLM is know what context they need?.&lt;/p&gt;
&lt;p&gt;first thing first what is &lt;strong&gt;RAG&lt;/strong&gt;? RAG is &lt;strong&gt;Retrieval Augmented Generation&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ollama Chat From Browser Using Nextjs</title>
      <link>https://teraskula.com/posts/ollama-chat-from-browser-using-nextjs/</link>
      <pubDate>Thu, 21 Nov 2024 00:31:49 +0700</pubDate>
      
      <guid>https://teraskula.com/posts/ollama-chat-from-browser-using-nextjs/</guid>
      <description>&lt;h3 id=&#34;ollama-chat-from-browser-using-nextjs&#34;&gt;Ollama Chat From Browser Using Nextjs&lt;/h3&gt;
&lt;p&gt;This writing will be so small.
it should be a step by step on creating nextjs app that will communicate with local ollama.
the model that i use is mistral its the fastest now running in my local.&lt;/p&gt;
&lt;p&gt;but instead starting from scrath, lets asking help to &lt;a href=&#34;bolt.new&#34;&gt;bolt.new&lt;/a&gt;
to create interface that will communicate with our ollama server in local.&lt;/p&gt;
&lt;p&gt;there is a reason why i learn this. i want to do &amp;hellip;. lets wait for another post ðŸ˜„&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Running Qwen in M2 Mac Air Machine using Ollama</title>
      <link>https://teraskula.com/posts/running-qwen-in-m2-mac-air-machine/</link>
      <pubDate>Wed, 20 Nov 2024 00:57:25 +0700</pubDate>
      
      <guid>https://teraskula.com/posts/running-qwen-in-m2-mac-air-machine/</guid>
      <description>&lt;h3 id=&#34;running-qwen-25-coder7b-on-macbook-air-m2-using-ollama&#34;&gt;Running qwen-2.5-coder:7B on macbook Air M2 using ollama&lt;/h3&gt;
&lt;p&gt;This is part of stay hungry stay folish mindset, and my interest in AI. Search possible solution to get cheapest code assistant as possible. i was subscribe to copilot but now after found &lt;a href=&#34;https://www.continue.dev/&#34;&gt;continue.dev&lt;/a&gt; + &lt;a href=&#34;https://www.anthropic.com/pricing#anthropic-api&#34;&gt;anthropic&lt;/a&gt; API, thats the current choice.&lt;/p&gt;
&lt;p&gt;Its small decrease in cost. copilot is $10 per month but now i am not that code heavy so subs to token based payment (anthropic claude 3.5 sonnet) is more cost effective. and pay base on what i use.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ChatGPT Open Ai, Is It Scary?</title>
      <link>https://teraskula.com/posts/chatgpt-open-ai-is-it-scary/</link>
      <pubDate>Fri, 09 Dec 2022 15:56:14 +0700</pubDate>
      
      <guid>https://teraskula.com/posts/chatgpt-open-ai-is-it-scary/</guid>
      <description>&lt;h2 id=&#34;chatgpt-is-it-scary&#34;&gt;ChatGPT is it scary?&lt;/h2&gt;
&lt;p&gt;it could be the end of yaml (kubernetes) engineers.&lt;/p&gt;
&lt;p&gt;there is phenomenon. in this time i write this post, i just try the viral AI in a programming world. openAI just released a product, or reasearch, or a robot called &lt;a href=&#34;https://openai.com/blog/chatgpt/&#34;&gt;chatGPT&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;they said&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Weâ€™ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests. ChatGPT is a sibling model to InstructGPT, which is trained to follow an instruction in a prompt and provide a detailed response.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
