<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Ai on teraskula.com</title>
    <link>http://localhost:1313/tags/ai/</link>
    <description>Recent content in Ai on teraskula.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Dec 2024 23:12:46 +0700</lastBuildDate><atom:link href="http://localhost:1313/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Langchain PDF Ollama RAG (Retrieval Augmented Generation)</title>
      <link>http://localhost:1313/posts/langchain-pdf-ollama-rag/</link>
      <pubDate>Mon, 02 Dec 2024 23:12:46 +0700</pubDate>
      
      <guid>http://localhost:1313/posts/langchain-pdf-ollama-rag/</guid>
      <description>&lt;h2 id=&#34;give-pdf-and-talk-about-it&#34;&gt;Give PDF and talk about it&lt;/h2&gt;
&lt;h4 id=&#34;using-lanchain-to-perform-rag-using-ollama-embedings-and-faiss-vectorstore&#34;&gt;using lanchain to perform RAG using Ollama embedings and FAISS vectorstore&lt;/h4&gt;
&lt;p&gt;yeah maybe many tools already provide this kind of feature, But this is different, this is about knowing behind the scene. what actually they do to the pdf files? what actually we do to the text in it? and how the LLM is know what context they need?.&lt;/p&gt;
&lt;p&gt;first thing first what is &lt;strong&gt;RAG&lt;/strong&gt;? RAG is &lt;strong&gt;Retrieval Augmented Generation&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ollama Chat From Browser Using Nextjs</title>
      <link>http://localhost:1313/posts/ollama-chat-from-browser-using-nextjs/</link>
      <pubDate>Thu, 21 Nov 2024 00:31:49 +0700</pubDate>
      
      <guid>http://localhost:1313/posts/ollama-chat-from-browser-using-nextjs/</guid>
      <description>&lt;h3 id=&#34;ollama-chat-from-browser-using-nextjs&#34;&gt;Ollama Chat From Browser Using Nextjs&lt;/h3&gt;
&lt;p&gt;This writing will be so small.
it should be a step by step on creating nextjs app that will communicate with local ollama.
the model that i use is mistral its the fastest now running in my local.&lt;/p&gt;
&lt;p&gt;but instead starting from scrath, lets asking help to &lt;a href=&#34;bolt.new&#34;&gt;bolt.new&lt;/a&gt;
to create interface that will communicate with our ollama server in local.&lt;/p&gt;
&lt;p&gt;there is a reason why i learn this. i want to do &amp;hellip;. lets wait for another post ðŸ˜„&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Running Qwen in M2 Mac Air Machine using Ollama</title>
      <link>http://localhost:1313/posts/running-qwen-in-m2-mac-air-machine/</link>
      <pubDate>Wed, 20 Nov 2024 00:57:25 +0700</pubDate>
      
      <guid>http://localhost:1313/posts/running-qwen-in-m2-mac-air-machine/</guid>
      <description>&lt;h3 id=&#34;running-qwen-25-coder7b-on-macbook-air-m2-using-ollama&#34;&gt;Running qwen-2.5-coder:7B on macbook Air M2 using ollama&lt;/h3&gt;
&lt;p&gt;This is part of stay hungry stay folish mindset, and my interest in AI. Search possible solution to get cheapest code assistant as possible. i was subscribe to copilot but now after found &lt;a href=&#34;https://www.continue.dev/&#34;&gt;continue.dev&lt;/a&gt; + &lt;a href=&#34;https://www.anthropic.com/pricing#anthropic-api&#34;&gt;anthropic&lt;/a&gt; API, thats the current choice.&lt;/p&gt;
&lt;p&gt;Its small decrease in cost. copilot is $10 per month but now i am not that code heavy so subs to token based payment (anthropic claude 3.5 sonnet) is more cost effective. and pay base on what i use.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ChatGPT Open Ai, Is It Scary?</title>
      <link>http://localhost:1313/posts/chatgpt-open-ai-is-it-scary/</link>
      <pubDate>Fri, 09 Dec 2022 15:56:14 +0700</pubDate>
      
      <guid>http://localhost:1313/posts/chatgpt-open-ai-is-it-scary/</guid>
      <description>&lt;h2 id=&#34;chatgpt-is-it-scary&#34;&gt;ChatGPT is it scary?&lt;/h2&gt;
&lt;p&gt;it could be the end of yaml (kubernetes) engineers.&lt;/p&gt;
&lt;p&gt;there is phenomenon. in this time i write this post, i just try the viral AI in a programming world. openAI just released a product, or reasearch, or a robot called &lt;a href=&#34;https://openai.com/blog/chatgpt/&#34;&gt;chatGPT&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;they said&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Weâ€™ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests. ChatGPT is a sibling model to InstructGPT, which is trained to follow an instruction in a prompt and provide a detailed response.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
